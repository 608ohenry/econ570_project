{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "https://www.cbp.gov/newsroom/stats\n",
    "\n",
    "https://www.ice.gov/detain/detention-management\n",
    "\n",
    "https://www.uscis.gov/tools/reports-and-studies/immigration-and-citizenship-data\n",
    "\n",
    "https://ohss.dhs.gov/topics/immigration#other-resources \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "- Write about H1B, H2A, H2B, or other visas\n",
    "- Write about detained individual counts at the border\n",
    "- Write about detained individuals within the US\n",
    "- Forecast immigration data\n",
    "- Forecast impacts of policy changes\n",
    "\n",
    "- Combine company visa information with their stock information\n",
    "- Investigate if there are any correlations between stock information and visa information\n",
    "- Can we make price movement predictions with visa information of publicly listed companies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from yfinance import ticker\n",
    "import json\n",
    "from io import StringIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a list of all listed companies from SEC's EDGAR database\n",
    "#\"https://www.sec.gov/files/company_tickers.json\"\n",
    "\n",
    "with open('data/company_tickers.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "# companies = [entry[\"ticker\"] for entry in response.values()]\n",
    "# print(companies[:10])  # Print first 10 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### More robust data wrangling pipeline once we get remove_meta_characters optimized / finish debugging files ###\n",
    "\n",
    "# def read_tsv(file_path):\n",
    "#     \"\"\"Reads a TSV file with UTF-8 encoding.\"\"\"\n",
    "#     with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
    "    \n",
    "# def remove_meta_characters(input_string):\n",
    "#     if pd.isna(input_string) or not isinstance(input_string, str):\n",
    "#         return \"\"\n",
    "#     # Define a regex pattern to match all meta characters\n",
    "#     cleaned_string = re.sub(r'^[A-Z0-9]+\\s+', '', input_string)\n",
    "#     cleaned_string = re.sub(r'[^\\w\\s]', '', cleaned_string)\n",
    "#     return cleaned_string.strip()\n",
    "\n",
    "# titles = [company['title'].upper() for company in data.values()]\n",
    "\n",
    "# visa_files = {\"h1b\": ['data/h1b_2016_2009.csv', 'data/h1b_2024_2017.csv'],\n",
    "#               \"h2a\": ['data/h2a_2019_2015.csv', 'data/h2a_2024_2020.csv'],\n",
    "#               \"h2b\": ['data/h2b_2019_2015.csv', 'data/h2b_2025_2020.csv']}\n",
    "\n",
    "# df_visas = []\n",
    "# for visa_type, files in visa_files.items():\n",
    "#     df_list = [read_tsv(file) for file in files]\n",
    "#     df = pd.concat(df_list, axis=0)\n",
    "#     df[\"employer\"] = df[\"Employer (Petitioner) Name\"].str.upper()#.apply(remove_meta_characters)\n",
    "#     df_filtered = df[df[\"employer\"].isin(titles)]\n",
    "#     df_filtered[\"type\"] = visa_type\n",
    "#     df_visas.append(df_filtered)\n",
    "\n",
    "# df_visas_combined = pd.concat(df_visas)\n",
    "\n",
    "# drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Index()', 'Consular_processed', 'New Employment Denial', 'Continuation Denial', 'Change with Same Employer Denial', 'New Concurrent Denial', 'Change of Employer Denial', 'Amended Denial', 'Consular_Processed', 'ETA Case Number']\n",
    "# df_visas_clean = df_visas_combined.drop(drop_cols, axis = 1)\n",
    "\n",
    "# df_visas_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3014528854.py:13: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3014528854.py:13: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3014528854.py:13: DtypeWarning: Columns (4,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3014528854.py:13: DtypeWarning: Columns (16,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h1b_2009_path = 'data/h1b_2016_2009.csv'\n",
    "h1b_2017_path = 'data/h1b_2024_2017.csv'\n",
    "\n",
    "h2a_2015_path = 'data/h2a_2019_2015.csv'\n",
    "h2a_2020_path = 'data/h2a_2024_2020.csv'\n",
    "\n",
    "h2b_2015_path = 'data/h2b_2019_2015.csv'\n",
    "h2b_2020_path = 'data/h2b_2025_2020.csv'\n",
    "\n",
    "#Had to convert all encoding to UTF8 via notepad++\n",
    "def read_tsv(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
    "\n",
    "# Read all files using the function\n",
    "df_h1b_a = read_tsv(h1b_2009_path)\n",
    "df_h1b_b = read_tsv(h1b_2017_path)\n",
    "\n",
    "df_h2a_a = read_tsv(h2a_2015_path)\n",
    "df_h2a_b = read_tsv(h2a_2020_path)\n",
    "\n",
    "df_h2b_a = read_tsv(h2b_2015_path)\n",
    "df_h2b_b = read_tsv(h2b_2020_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1b = pd.concat([df_h1b_a, df_h1b_b], axis=0)\n",
    "\n",
    "df_h2a = pd.concat([df_h2a_a, df_h2a_b], axis=0)\n",
    "\n",
    "df_h2b = pd.concat([df_h2b_a, df_h2b_b], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
      "       'Initial Denial', 'Continuing Approval', 'Continuing Denial'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Action Fiscal Year', 'Employer (Petitioner) Name', 'Tax ID',\n",
      "       'Industry', 'Occupation (SOC) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Worksite State',\n",
      "       'Consular_processed', 'Wage Rate Band', 'New Employment Approval',\n",
      "       'New Employment Denial', 'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Cap Fiscal Year', 'Cap Type', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Occupation (SOC) Code',\n",
      "       'Petitioner City', 'Petitioner State', 'Petitioner Zip Code',\n",
      "       'Work Site State', 'Consular_Processed', 'Hourly Wage',\n",
      "       'ETA Case Number', 'New Employment Approval', 'New Employment Denial',\n",
      "       'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_h1b.columns)\n",
    "print(df_h2a.columns)\n",
    "print(df_h2b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [company['title'].upper() for company in data.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meta_characters(input_string):\n",
    "    # Define a regex pattern to match all meta characters\n",
    "    pattern = r'[^\\w\\s]'\n",
    "    # Substitute meta characters with an empty string\n",
    "    cleaned_string = re.sub(pattern, '', input_string)\n",
    "    return cleaned_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1b['employer'] = df_h1b['Employer (Petitioner) Name'].str.upper()\n",
    "df_h2a['employer'] = df_h2a['Employer (Petitioner) Name'].str.upper()\n",
    "df_h2b['employer'] = df_h2b['Employer (Petitioner) Name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample H2A Matches:      employer\n",
      "3511  CHS INC\n",
      "3512  CHS INC\n",
      "Sample H2B Matches:                         employer\n",
      "3876                     UTG INC\n",
      "9245  GREEN LEAF INNOVATIONS INC\n"
     ]
    }
   ],
   "source": [
    "# print(df_h2a[['Employer (Petitioner) Name', 'employer']].head(10))\n",
    "print(\"Sample H2A Matches:\", df_h2a[df_h2a[\"employer\"].isin(titles)][[\"employer\"]].head(2))\n",
    "print(\"Sample H2B Matches:\", df_h2b[df_h2b[\"employer\"].isin(titles)][[\"employer\"]].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1B Crossover Count 5245\n",
      "H2A Crossover Count 53\n",
      "H2B Crossover Count 4\n"
     ]
    }
   ],
   "source": [
    "print('H1B Crossover Count ' + str(sum(df_h1b[\"employer\"].isin(titles))))\n",
    "print('H2A Crossover Count ' + str(sum(df_h2a[\"employer\"].isin(titles))))\n",
    "print('H2B Crossover Count ' + str(sum(df_h2b[\"employer\"].isin(titles))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3144496779.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_h1b_listed['type'] = 'h1b'\n",
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3144496779.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_h2a_listed['type'] = 'h2a'\n",
      "C:\\Users\\owenh\\AppData\\Local\\Temp\\ipykernel_12284\\3144496779.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_h2b_listed['type'] = 'h2b'\n"
     ]
    }
   ],
   "source": [
    "df_h1b_listed = df_h1b[ df_h1b[\"employer\"].isin(titles) ]\n",
    "df_h1b_listed['type'] = 'h1b'\n",
    "\n",
    "df_h2a_listed = df_h2a[ df_h2a[\"employer\"].isin(titles) ]\n",
    "df_h2a_listed['type'] = 'h2a'\n",
    "\n",
    "df_h2b_listed = df_h2b[ df_h2b[\"employer\"].isin(titles) ]\n",
    "df_h2b_listed['type'] = 'h2b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
      "       'Initial Denial', 'Continuing Approval', 'Continuing Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Action Fiscal Year', 'Employer (Petitioner) Name', 'Tax ID',\n",
      "       'Industry', 'Occupation (SOC) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Worksite State',\n",
      "       'Consular_processed', 'Wage Rate Band', 'New Employment Approval',\n",
      "       'New Employment Denial', 'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Cap Fiscal Year', 'Cap Type', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Occupation (SOC) Code',\n",
      "       'Petitioner City', 'Petitioner State', 'Petitioner Zip Code',\n",
      "       'Work Site State', 'Consular_Processed', 'Hourly Wage',\n",
      "       'ETA Case Number', 'New Employment Approval', 'New Employment Denial',\n",
      "       'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_h1b.columns)\n",
    "print(df_h2a.columns)\n",
    "print(df_h2b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5302, 39)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas = pd.concat([df_h1b_listed, df_h2a_listed, df_h2b_listed])\n",
    "df_visas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h1b_drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Initial Approval', 'Continuing Approval']\n",
    "#Adding the columns does not work since they are currently strings, to_numeric not working due to commas\n",
    "df_h1b_listed['tot'] = df_h1b_listed['Initial Approval'] + df_h1b_listed['Continuing Approval']\n",
    "df_h1b_clean = df_h1b_listed.drop(h1b_drop_cols, axis = 1)\n",
    "df_h1b_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
       "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
       "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
       "       'Initial Denial', 'Continuing Approval', 'Continuing Denial',\n",
       "       'employer', 'type', 'Index()', 'Action Fiscal Year', 'Industry',\n",
       "       'Occupation (SOC) Code', 'Worksite State', 'Consular_processed',\n",
       "       'Wage Rate Band', 'New Employment Approval', 'New Employment Denial',\n",
       "       'Continuation Approval', 'Continuation Denial',\n",
       "       'Change with Same Employer Approval',\n",
       "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
       "       'New Concurrent Denial', 'Change of Employer Approval',\n",
       "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
       "       'Cap Fiscal Year', 'Cap Type', 'Work Site State', 'Consular_Processed',\n",
       "       'Hourly Wage', 'ETA Case Number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Index()', 'Consular_processed', 'New Employment Denial', 'Continuation Denial', 'Change with Same Employer Denial', 'New Concurrent Denial', 'Change of Employer Denial', 'Amended Denial', 'Consular_Processed', 'ETA Case Number']\n",
    "df_visas_clean = df_visas.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fiscal Year</th>\n",
       "      <th>Industry (NAICS) Code</th>\n",
       "      <th>Petitioner City</th>\n",
       "      <th>Petitioner State</th>\n",
       "      <th>Petitioner Zip Code</th>\n",
       "      <th>Initial Approval</th>\n",
       "      <th>Continuing Approval</th>\n",
       "      <th>employer</th>\n",
       "      <th>type</th>\n",
       "      <th>Action Fiscal Year</th>\n",
       "      <th>...</th>\n",
       "      <th>New Employment Approval</th>\n",
       "      <th>Continuation Approval</th>\n",
       "      <th>Change with Same Employer Approval</th>\n",
       "      <th>New Concurrent Approval</th>\n",
       "      <th>Change of Employer Approval</th>\n",
       "      <th>Amended Approval</th>\n",
       "      <th>Cap Fiscal Year</th>\n",
       "      <th>Cap Type</th>\n",
       "      <th>Work Site State</th>\n",
       "      <th>Hourly Wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORTH CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60064.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>ABBOT PARK</td>\n",
       "      <td>IL</td>\n",
       "      <td>60064.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>ABBOTT PARK</td>\n",
       "      <td>IL</td>\n",
       "      <td>60064.0</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>NORTH CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>60064.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>54 - Professional, Scientific, and Technical S...</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>CA</td>\n",
       "      <td>92130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ACADIA PHARMACEUTICALS INC</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fiscal Year                                 Industry (NAICS) Code  \\\n",
       "547          2016.0                                                NaN   \n",
       "548          2016.0                              31-33 - Manufacturing   \n",
       "549          2016.0                              31-33 - Manufacturing   \n",
       "550          2016.0                              31-33 - Manufacturing   \n",
       "694          2016.0  54 - Professional, Scientific, and Technical S...   \n",
       "\n",
       "    Petitioner City Petitioner State  Petitioner Zip Code Initial Approval  \\\n",
       "547   NORTH CHICAGO               IL              60064.0                1   \n",
       "548      ABBOT PARK               IL              60064.0                0   \n",
       "549     ABBOTT PARK               IL              60064.0                2   \n",
       "550   NORTH CHICAGO               IL              60064.0                0   \n",
       "694       SAN DIEGO               CA              92130.0                1   \n",
       "\n",
       "    Continuing Approval                    employer type  Action Fiscal Year  \\\n",
       "547                   1         ABBOTT LABORATORIES  h1b                 NaN   \n",
       "548                   1         ABBOTT LABORATORIES  h1b                 NaN   \n",
       "549                  41         ABBOTT LABORATORIES  h1b                 NaN   \n",
       "550                   5         ABBOTT LABORATORIES  h1b                 NaN   \n",
       "694                   1  ACADIA PHARMACEUTICALS INC  h1b                 NaN   \n",
       "\n",
       "     ... New Employment Approval Continuation Approval  \\\n",
       "547  ...                     NaN                   NaN   \n",
       "548  ...                     NaN                   NaN   \n",
       "549  ...                     NaN                   NaN   \n",
       "550  ...                     NaN                   NaN   \n",
       "694  ...                     NaN                   NaN   \n",
       "\n",
       "    Change with Same Employer Approval New Concurrent Approval  \\\n",
       "547                                NaN                     NaN   \n",
       "548                                NaN                     NaN   \n",
       "549                                NaN                     NaN   \n",
       "550                                NaN                     NaN   \n",
       "694                                NaN                     NaN   \n",
       "\n",
       "    Change of Employer Approval Amended Approval Cap Fiscal Year Cap Type  \\\n",
       "547                         NaN              NaN             NaN      NaN   \n",
       "548                         NaN              NaN             NaN      NaN   \n",
       "549                         NaN              NaN             NaN      NaN   \n",
       "550                         NaN              NaN             NaN      NaN   \n",
       "694                         NaN              NaN             NaN      NaN   \n",
       "\n",
       "    Work Site State  Hourly Wage  \n",
       "547             NaN          NaN  \n",
       "548             NaN          NaN  \n",
       "549             NaN          NaN  \n",
       "550             NaN          NaN  \n",
       "694             NaN          NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def fetch_stock_data(tickers):\n",
    "    all_data = {}\n",
    "    print('Downloading yfinance historical price data 2000/01/01 to 2025/03/16')\n",
    "    num_downloaded = 0\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = yf.download(ticker, start=\"2000-01-01\", end=\"2025-03-16\", progress = False)\n",
    "            all_data[ticker] = data\n",
    "            num_downloaded +=1\n",
    "            time.sleep(2.2)  # Sleep for 2 seconds between requests to avoid being blocked\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "            time.sleep(2.2)\n",
    "\n",
    "    print('Successfully downloaded ' + str(num_downloaded/len(tickers)))\n",
    "    #Save a csv for offline work\n",
    "    sp500_data = pd.concat(all_data, axis=1)\n",
    "    sp500_data.to_csv(\"sp500_data.csv\")\n",
    "    \n",
    "    print(\"S&P 500 historical data saved to sp500_data.csv\")\n",
    "    return sp500_data\n",
    "\n",
    "#Only run this once on your system\n",
    "#Make sure NOT to track the sp500_data csv\n",
    "#sp500csv made for offline work\n",
    "#fetch_stock_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
