{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "https://www.cbp.gov/newsroom/stats\n",
    "\n",
    "https://www.ice.gov/detain/detention-management\n",
    "\n",
    "https://www.uscis.gov/tools/reports-and-studies/immigration-and-citizenship-data\n",
    "\n",
    "https://ohss.dhs.gov/topics/immigration#other-resources \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "- Write about H1B, H2A, H2B, or other visas\n",
    "- Write about detained individual counts at the border\n",
    "- Write about detained individuals within the US\n",
    "- Forecast immigration data\n",
    "- Forecast impacts of policy changes\n",
    "\n",
    "- Combine company visa information with their stock information\n",
    "- Investigate if there are any correlations between stock information and visa information\n",
    "- Can we make price movement predictions with visa information of publicly listed companies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from yfinance import ticker\n",
    "import json\n",
    "from io import StringIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a list of all listed companies from SEC's EDGAR database\n",
    "#\"https://www.sec.gov/files/company_tickers.json\"\n",
    "\n",
    "with open('data/company_tickers.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "# companies = [entry[\"ticker\"] for entry in response.values()]\n",
    "# print(companies[:10])  # Print first 10 tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\2973020064.py:6: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\2973020064.py:6: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\2973020064.py:6: DtypeWarning: Columns (4,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\2973020064.py:6: DtypeWarning: Columns (16,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19349, 24)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### More robust data wrangling pipeline once we get remove_meta_characters optimized / finish debugging files ###\n",
    "\n",
    "def read_tsv(file_path):\n",
    "    \"\"\"Reads a TSV file with UTF-8 encoding.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
    "    \n",
    "def remove_meta_characters(input_string):\n",
    "    input_string = str(input_string)\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip() \n",
    "    input_string = re.sub(r'\\b(INCORPORATED|INC|CORPORATION|CORP|NA|N A|LTD|LIMITED|LLC|LLP|PLC|GROUP|GRP|GR|HOLDINGS|COMPANY|CO|LP|PARTNERSHIP)\\b',\n",
    "                          '', str(input_string).upper())\n",
    "    input_string = re.sub(r'/[^/]+/', ' ', input_string)\n",
    "    input_string = input_string.replace('.', '').replace(',', '').replace('&', 'AND')\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip() \n",
    "    return input_string\n",
    "\n",
    "titles = [company['title'].upper() for company in data.values()]\n",
    "standard_titles = [remove_meta_characters(title) for title in titles]\n",
    "\n",
    "visa_files = {\"h1b\": ['data/h1b_2016_2009.csv', 'data/h1b_2024_2017.csv'],\n",
    "              \"h2a\": ['data/h2a_2019_2015.csv', 'data/h2a_2024_2020.csv'],\n",
    "              \"h2b\": ['data/h2b_2019_2015.csv', 'data/h2b_2025_2020.csv']}\n",
    "\n",
    "df_visas = []\n",
    "for visa_type, files in visa_files.items():\n",
    "    df_list = [read_tsv(file) for file in files]\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    df[\"employer\"] = df[\"Employer (Petitioner) Name\"].str.upper().apply(remove_meta_characters)\n",
    "    df_filtered = df[df[\"employer\"].isin(standard_titles)].copy()\n",
    "    df_filtered.loc[:, \"type\"] = visa_type\n",
    "    df_visas.append(df_filtered)\n",
    " \n",
    "df_visas_combined = pd.concat(df_visas)\n",
    "\n",
    "drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Index()', 'Consular_processed', 'New Employment Denial', 'Continuation Denial', 'Change with Same Employer Denial', 'New Concurrent Denial', 'Change of Employer Denial', 'Amended Denial', 'Consular_Processed', 'ETA Case Number']\n",
    "df_visas_clean = df_visas_combined.drop(drop_cols, axis = 1)\n",
    "\n",
    "df_visas_clean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\3014528854.py:13: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\3014528854.py:13: DtypeWarning: Columns (9,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\3014528854.py:13: DtypeWarning: Columns (4,16,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
      "C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_22096\\3014528854.py:13: DtypeWarning: Columns (16,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h1b_2009_path = 'data/h1b_2016_2009.csv'\n",
    "h1b_2017_path = 'data/h1b_2024_2017.csv'\n",
    "\n",
    "h2a_2015_path = 'data/h2a_2019_2015.csv'\n",
    "h2a_2020_path = 'data/h2a_2024_2020.csv'\n",
    "\n",
    "h2b_2015_path = 'data/h2b_2019_2015.csv'\n",
    "h2b_2020_path = 'data/h2b_2025_2020.csv'\n",
    "\n",
    "#Had to convert all encoding to UTF8 via notepad++\n",
    "def read_tsv(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return pd.read_csv(StringIO(f.read()), delimiter=\"\\t\")\n",
    "\n",
    "# Read all files using the function\n",
    "df_h1b_a = read_tsv(h1b_2009_path)\n",
    "df_h1b_b = read_tsv(h1b_2017_path)\n",
    "\n",
    "df_h2a_a = read_tsv(h2a_2015_path)\n",
    "df_h2a_b = read_tsv(h2a_2020_path)\n",
    "\n",
    "df_h2b_a = read_tsv(h2b_2015_path)\n",
    "df_h2b_b = read_tsv(h2b_2020_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1b = pd.concat([df_h1b_a, df_h1b_b], axis=0)\n",
    "\n",
    "df_h2a = pd.concat([df_h2a_a, df_h2a_b], axis=0)\n",
    "\n",
    "df_h2b = pd.concat([df_h2b_a, df_h2b_b], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
      "       'Initial Denial', 'Continuing Approval', 'Continuing Denial'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Action Fiscal Year', 'Employer (Petitioner) Name', 'Tax ID',\n",
      "       'Industry', 'Occupation (SOC) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Worksite State',\n",
      "       'Consular_processed', 'Wage Rate Band', 'New Employment Approval',\n",
      "       'New Employment Denial', 'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Cap Fiscal Year', 'Cap Type', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Occupation (SOC) Code',\n",
      "       'Petitioner City', 'Petitioner State', 'Petitioner Zip Code',\n",
      "       'Work Site State', 'Consular_Processed', 'Hourly Wage',\n",
      "       'ETA Case Number', 'New Employment Approval', 'New Employment Denial',\n",
      "       'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_h1b.columns)\n",
    "print(df_h2a.columns)\n",
    "print(df_h2b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_meta_characters(input_string):\n",
    "    input_string = str(input_string)\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip() \n",
    "    input_string = re.sub(r'\\b(INCORPORATED|INC|CORPORATION|CORP|NA|N A|LTD|LIMITED|LLC|LLP|PLC|GROUP|GRP|GR|HOLDINGS|COMPANY|CO|LP|PARTNERSHIP)\\b',\n",
    "                          '', str(input_string).upper())\n",
    "    input_string = re.sub(r'/[^/]+/', ' ', input_string)\n",
    "    input_string = input_string.replace('.', '').replace(',', '').replace('&', 'AND')\n",
    "    input_string = re.sub(r'\\s+', ' ', input_string).strip() \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [company['title'].upper() for company in data.values()]\n",
    "\n",
    "standard_titles = [remove_meta_characters(title) for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1b['employer'] = df_h1b['Employer (Petitioner) Name'].str.upper().apply(remove_meta_characters)\n",
    "df_h2a['employer'] = df_h2a['Employer (Petitioner) Name'].str.upper().apply(remove_meta_characters)\n",
    "df_h2b['employer'] = df_h2b['Employer (Petitioner) Name'].str.upper().apply(remove_meta_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1B Crossover Count: 19226\n",
      "H2A Crossover Count: 73\n",
      "H2B Crossover Count: 50\n"
     ]
    }
   ],
   "source": [
    "print('H1B Crossover Count: ' + str(sum(df_h1b[\"employer\"].isin(standard_titles))))\n",
    "print('H2A Crossover Count: ' + str(sum(df_h2a[\"employer\"].isin(standard_titles))))\n",
    "print('H2B Crossover Count: ' + str(sum(df_h2b[\"employer\"].isin(standard_titles))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h1b_listed = df_h1b[ df_h1b[\"employer\"].isin(standard_titles) ].copy()\n",
    "df_h1b_listed.loc[:, \"type\"] = 'h1b'\n",
    "\n",
    "df_h2a_listed = df_h2a[ df_h2a[\"employer\"].isin(standard_titles) ].copy()\n",
    "df_h2a_listed.loc[:, \"type\"] = 'h2a'\n",
    "\n",
    "df_h2b_listed = df_h2b[ df_h2b[\"employer\"].isin(standard_titles) ].copy()\n",
    "df_h2b_listed.loc[:, \"type\"] = 'h2b'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
      "       'Initial Denial', 'Continuing Approval', 'Continuing Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Action Fiscal Year', 'Employer (Petitioner) Name', 'Tax ID',\n",
      "       'Industry', 'Occupation (SOC) Code', 'Petitioner City',\n",
      "       'Petitioner State', 'Petitioner Zip Code', 'Worksite State',\n",
      "       'Consular_processed', 'Wage Rate Band', 'New Employment Approval',\n",
      "       'New Employment Denial', 'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n",
      "Index(['Index()', 'Cap Fiscal Year', 'Cap Type', 'Employer (Petitioner) Name',\n",
      "       'Tax ID', 'Industry (NAICS) Code', 'Occupation (SOC) Code',\n",
      "       'Petitioner City', 'Petitioner State', 'Petitioner Zip Code',\n",
      "       'Work Site State', 'Consular_Processed', 'Hourly Wage',\n",
      "       'ETA Case Number', 'New Employment Approval', 'New Employment Denial',\n",
      "       'Continuation Approval', 'Continuation Denial',\n",
      "       'Change with Same Employer Approval',\n",
      "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
      "       'New Concurrent Denial', 'Change of Employer Approval',\n",
      "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
      "       'employer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_h1b.columns)\n",
    "print(df_h2a.columns)\n",
    "print(df_h2b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13610, 39)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas = pd.concat([df_h1b_listed, df_h2a_listed, df_h2b_listed])\n",
    "df_visas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h1b_drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Initial Approval', 'Continuing Approval']\n",
    "#Adding the columns does not work since they are currently strings, to_numeric not working due to commas\n",
    "df_h1b_listed['tot'] = df_h1b_listed['Initial Approval'] + df_h1b_listed['Continuing Approval']\n",
    "df_h1b_clean = df_h1b_listed.drop(h1b_drop_cols, axis = 1)\n",
    "df_h1b_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Line by line', 'Fiscal Year   ', 'Employer (Petitioner) Name',\n",
       "       'Tax ID', 'Industry (NAICS) Code', 'Petitioner City',\n",
       "       'Petitioner State', 'Petitioner Zip Code', 'Initial Approval',\n",
       "       'Initial Denial', 'Continuing Approval', 'Continuing Denial',\n",
       "       'employer', 'type', 'Index()', 'Action Fiscal Year', 'Industry',\n",
       "       'Occupation (SOC) Code', 'Worksite State', 'Consular_processed',\n",
       "       'Wage Rate Band', 'New Employment Approval', 'New Employment Denial',\n",
       "       'Continuation Approval', 'Continuation Denial',\n",
       "       'Change with Same Employer Approval',\n",
       "       'Change with Same Employer Denial', 'New Concurrent Approval',\n",
       "       'New Concurrent Denial', 'Change of Employer Approval',\n",
       "       'Change of Employer Denial', 'Amended Approval', 'Amended Denial',\n",
       "       'Cap Fiscal Year', 'Cap Type', 'Work Site State', 'Consular_Processed',\n",
       "       'Hourly Wage', 'ETA Case Number'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Line by line', 'Employer (Petitioner) Name', 'Tax ID', 'Initial Denial', 'Continuing Denial', 'Index()', 'Consular_processed', 'New Employment Denial', 'Continuation Denial', 'Change with Same Employer Denial', 'New Concurrent Denial', 'Change of Employer Denial', 'Amended Denial', 'Consular_Processed', 'ETA Case Number']\n",
    "df_visas_clean = df_visas.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fiscal Year</th>\n",
       "      <th>Industry (NAICS) Code</th>\n",
       "      <th>Petitioner City</th>\n",
       "      <th>Petitioner State</th>\n",
       "      <th>Petitioner Zip Code</th>\n",
       "      <th>Initial Approval</th>\n",
       "      <th>Continuing Approval</th>\n",
       "      <th>employer</th>\n",
       "      <th>type</th>\n",
       "      <th>Action Fiscal Year</th>\n",
       "      <th>...</th>\n",
       "      <th>New Employment Approval</th>\n",
       "      <th>Continuation Approval</th>\n",
       "      <th>Change with Same Employer Approval</th>\n",
       "      <th>New Concurrent Approval</th>\n",
       "      <th>Change of Employer Approval</th>\n",
       "      <th>Amended Approval</th>\n",
       "      <th>Cap Fiscal Year</th>\n",
       "      <th>Cap Type</th>\n",
       "      <th>Work Site State</th>\n",
       "      <th>Hourly Wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>ROCK HILL</td>\n",
       "      <td>SC</td>\n",
       "      <td>29730.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3D SYSTEMS</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>SAINT PAUL</td>\n",
       "      <td>MN</td>\n",
       "      <td>55144.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3M</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>31-33 - Manufacturing</td>\n",
       "      <td>ST PAUL</td>\n",
       "      <td>MN</td>\n",
       "      <td>55144.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3M</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAN JOSE</td>\n",
       "      <td>CA</td>\n",
       "      <td>95131.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8X8</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>54 - Professional, Scientific, and Technical S...</td>\n",
       "      <td>SAN JOSE</td>\n",
       "      <td>CA</td>\n",
       "      <td>95131.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8X8</td>\n",
       "      <td>h1b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fiscal Year                                 Industry (NAICS) Code  \\\n",
       "63           2016.0                              31-33 - Manufacturing   \n",
       "81           2016.0                              31-33 - Manufacturing   \n",
       "82           2016.0                              31-33 - Manufacturing   \n",
       "179          2016.0                                                NaN   \n",
       "180          2016.0  54 - Professional, Scientific, and Technical S...   \n",
       "\n",
       "    Petitioner City Petitioner State  Petitioner Zip Code Initial Approval  \\\n",
       "63        ROCK HILL               SC              29730.0                0   \n",
       "81       SAINT PAUL               MN              55144.0                4   \n",
       "82          ST PAUL               MN              55144.0                2   \n",
       "179        SAN JOSE               CA              95131.0               12   \n",
       "180        SAN JOSE               CA              95131.0                0   \n",
       "\n",
       "    Continuing Approval    employer type  Action Fiscal Year  ...  \\\n",
       "63                    7  3D SYSTEMS  h1b                 NaN  ...   \n",
       "81                   13          3M  h1b                 NaN  ...   \n",
       "82                    8          3M  h1b                 NaN  ...   \n",
       "179                   8         8X8  h1b                 NaN  ...   \n",
       "180                   1         8X8  h1b                 NaN  ...   \n",
       "\n",
       "    New Employment Approval Continuation Approval  \\\n",
       "63                      NaN                   NaN   \n",
       "81                      NaN                   NaN   \n",
       "82                      NaN                   NaN   \n",
       "179                     NaN                   NaN   \n",
       "180                     NaN                   NaN   \n",
       "\n",
       "    Change with Same Employer Approval New Concurrent Approval  \\\n",
       "63                                 NaN                     NaN   \n",
       "81                                 NaN                     NaN   \n",
       "82                                 NaN                     NaN   \n",
       "179                                NaN                     NaN   \n",
       "180                                NaN                     NaN   \n",
       "\n",
       "    Change of Employer Approval Amended Approval Cap Fiscal Year Cap Type  \\\n",
       "63                          NaN              NaN             NaN      NaN   \n",
       "81                          NaN              NaN             NaN      NaN   \n",
       "82                          NaN              NaN             NaN      NaN   \n",
       "179                         NaN              NaN             NaN      NaN   \n",
       "180                         NaN              NaN             NaN      NaN   \n",
       "\n",
       "    Work Site State  Hourly Wage  \n",
       "63              NaN          NaN  \n",
       "81              NaN          NaN  \n",
       "82              NaN          NaN  \n",
       "179             NaN          NaN  \n",
       "180             NaN          NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visas_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def fetch_stock_data(tickers):\n",
    "    all_data = {}\n",
    "    print('Downloading yfinance historical price data 2000/01/01 to 2025/03/16')\n",
    "    num_downloaded = 0\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            data = yf.download(ticker, start=\"2000-01-01\", end=\"2025-03-16\", progress = False)\n",
    "            all_data[ticker] = data\n",
    "            num_downloaded +=1\n",
    "            time.sleep(2.2)  # Sleep for 2 seconds between requests to avoid being blocked\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {ticker}: {e}\")\n",
    "            time.sleep(2.2)\n",
    "\n",
    "    print('Successfully downloaded ' + str(num_downloaded/len(tickers)))\n",
    "    #Save a csv for offline work\n",
    "    sp500_data = pd.concat(all_data, axis=1)\n",
    "    sp500_data.to_csv(\"sp500_data.csv\")\n",
    "    \n",
    "    print(\"S&P 500 historical data saved to sp500_data.csv\")\n",
    "    return sp500_data\n",
    "\n",
    "#Only run this once on your system\n",
    "#Make sure NOT to track the sp500_data csv\n",
    "#sp500csv made for offline work\n",
    "#fetch_stock_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ570",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
